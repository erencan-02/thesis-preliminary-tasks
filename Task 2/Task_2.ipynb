{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Time Series\n",
    "Define, train, and test an ML model (preferably a neural network) to recognize the activity being performed in the following human activity recognition dataset: https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
    "       'WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(task_number, *args):\n",
    "    notebook_path = os.path.abspath(f\"Task_{task_number}.ipynb\")\n",
    "    return os.path.join(os.path.dirname(notebook_path), *args)\n",
    "\n",
    "def preprocess_data(df, column=\"Activity\"):\n",
    "    le = LabelEncoder()\n",
    "    return  df.drop(column, axis=1), le.fit_transform(df[column])\n",
    "\n",
    "# Convert numpy array of output lables to one hot encoded tensor\n",
    "def get_output_tensor(array):\n",
    "    tensor = torch.zeros((len(array), 6), dtype=torch.float32)\n",
    "    for i, val in enumerate(array):\n",
    "        tensor[i][val] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Data Into Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.298676   \n",
       "1         -0.957686         -0.943068  ...                        -0.595051   \n",
       "2         -0.977469         -0.938692  ...                        -0.390748   \n",
       "3         -0.989302         -0.938692  ...                        -0.117290   \n",
       "4         -0.990441         -0.942469  ...                        -0.351471   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  subject  \n",
       "0              0.179941             -0.058627        1  \n",
       "1              0.180289             -0.054317        1  \n",
       "2              0.180637             -0.049118        1  \n",
       "3              0.181935             -0.047663        1  \n",
       "4              0.185151             -0.043892        1  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = get_path(2, \"model\", \"fashion_mnist_cnn.pt\")\n",
    "\n",
    "train_data = pd.read_csv(get_path(2, \"data\", \"train.csv\"))\n",
    "test_data = pd.read_csv(get_path(2, \"data\", \"test.csv\"))\n",
    "\n",
    "# Split into label and features\n",
    "train_data, train_labels = preprocess_data(train_data)\n",
    "test_data, test_labels = preprocess_data(test_data)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network\n",
    "In this case we want an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = self.fc3(out)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Network and Training Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-2\n",
    "batch_size = 5\n",
    "num_epochs = 10\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = MLP(562, 100, 6).to(device)\n",
    "model.train()\n",
    "\n",
    "# setup loss function and optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [0/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [2/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [3/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [4/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [5/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [6/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [7/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [8/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [9/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [10/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [11/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [12/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [13/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [14/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [15/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [16/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [17/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [18/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [19/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [20/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [21/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [22/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [23/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [24/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [25/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [26/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [27/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [28/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [29/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [30/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [31/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [32/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [33/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [34/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [35/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [36/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [37/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [38/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [39/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [40/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [41/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [42/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [43/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [44/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [45/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [46/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [47/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [48/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [49/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [50/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [51/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [52/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [53/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [54/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [55/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [56/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [57/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [58/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [59/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [60/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [61/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [62/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [63/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [64/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [65/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [66/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [67/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [68/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [69/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [70/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [71/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [72/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [73/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [74/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [75/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [76/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [77/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [78/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [79/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [80/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [81/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [82/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [83/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [84/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [85/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [86/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [87/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [88/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [89/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [90/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [91/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [92/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [93/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [94/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [95/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [96/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [97/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [98/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [99/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [100/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [101/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [102/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [103/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [104/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [105/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [106/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [107/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [108/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [109/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [110/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [111/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [112/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [113/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [114/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [115/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [116/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [117/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [118/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [119/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [120/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [121/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [122/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [123/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [124/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [125/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [126/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [127/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [128/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [129/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [130/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [131/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [132/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [133/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [134/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [135/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [136/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [137/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [138/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [139/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [140/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [141/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [142/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [143/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [144/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [145/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [146/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [147/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [148/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [149/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [150/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [151/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [152/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [153/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [154/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [155/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [156/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [157/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [158/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [159/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [160/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [161/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [162/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [163/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [164/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [165/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [166/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [167/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [168/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [169/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [170/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [171/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [172/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [173/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [174/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [175/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [176/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [177/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [178/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [179/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [180/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [181/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [182/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [183/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [184/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [185/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [186/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [187/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [188/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [189/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [190/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [191/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [192/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [193/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [194/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [195/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [196/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [197/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [198/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [199/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [200/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [201/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [202/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [203/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [204/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [205/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [206/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [207/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [208/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [209/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [210/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [211/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [212/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [213/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [214/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [215/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [216/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [217/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [218/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [219/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [220/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [221/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [222/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [223/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [224/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [225/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [226/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [227/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [228/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [229/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [230/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [231/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [232/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [233/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [234/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [235/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [236/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [237/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [238/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [239/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [240/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [241/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [242/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [243/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [244/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [245/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [246/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [247/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [248/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [249/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [250/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [251/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [252/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [253/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [254/1470], Loss: 1.7961\n",
      "Epoch [1/10], Step [255/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [256/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [257/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [258/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [259/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [260/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [261/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [262/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [263/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [264/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [265/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [266/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [267/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [268/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [269/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [270/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [271/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [272/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [273/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [274/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [275/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [276/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [277/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [278/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [279/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [280/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [281/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [282/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [283/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [284/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [285/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [286/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [287/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [288/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [289/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [290/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [291/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [292/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [293/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [294/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [295/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [296/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [297/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [298/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [299/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [300/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [301/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [302/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [303/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [304/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [305/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [306/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [307/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [308/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [309/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [310/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [311/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [312/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [313/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [314/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [315/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [316/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [317/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [318/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [319/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [320/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [321/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [322/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [323/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [324/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [325/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [326/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [327/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [328/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [329/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [330/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [331/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [332/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [333/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [334/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [335/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [336/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [337/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [338/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [339/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [340/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [341/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [342/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [343/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [344/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [345/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [346/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [347/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [348/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [349/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [350/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [351/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [352/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [353/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [354/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [355/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [356/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [357/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [358/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [359/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [360/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [361/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [362/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [363/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [364/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [365/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [366/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [367/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [368/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [369/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [370/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [371/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [372/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [373/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [374/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [375/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [376/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [377/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [378/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [379/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [380/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [381/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [382/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [383/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [384/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [385/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [386/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [387/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [388/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [389/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [390/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [391/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [392/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [393/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [394/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [395/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [396/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [397/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [398/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [399/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [400/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [401/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [402/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [403/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [404/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [405/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [406/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [407/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [408/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [409/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [410/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [411/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [412/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [413/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [414/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [415/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [416/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [417/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [418/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [419/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [420/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [421/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [422/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [423/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [424/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [425/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [426/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [427/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [428/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [429/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [430/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [431/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [432/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [433/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [434/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [435/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [436/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [437/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [438/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [439/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [440/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [441/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [442/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [443/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [444/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [445/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [446/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [447/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [448/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [449/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [450/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [451/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [452/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [453/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [454/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [455/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [456/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [457/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [458/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [459/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [460/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [461/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [462/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [463/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [464/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [465/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [466/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [467/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [468/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [469/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [470/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [471/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [472/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [473/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [474/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [475/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [476/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [477/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [478/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [479/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [480/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [481/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [482/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [483/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [484/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [485/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [486/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [487/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [488/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [489/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [490/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [491/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [492/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [493/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [494/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [495/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [496/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [497/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [498/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [499/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [500/1470], Loss: 1.7923\n",
      "Epoch [1/10], Step [501/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [502/1470], Loss: 1.7930\n",
      "Epoch [1/10], Step [503/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [504/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [505/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [506/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [507/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [508/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [509/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [510/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [511/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [512/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [513/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [514/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [515/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [516/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [517/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [518/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [519/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [520/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [521/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [522/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [523/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [524/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [525/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [526/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [527/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [528/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [529/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [530/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [531/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [532/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [533/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [534/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [535/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [536/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [537/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [538/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [539/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [540/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [541/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [542/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [543/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [544/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [545/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [546/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [547/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [548/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [549/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [550/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [551/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [552/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [553/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [554/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [555/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [556/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [557/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [558/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [559/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [560/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [561/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [562/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [563/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [564/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [565/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [566/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [567/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [568/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [569/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [570/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [571/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [572/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [573/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [574/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [575/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [576/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [577/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [578/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [579/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [580/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [581/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [582/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [583/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [584/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [585/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [586/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [587/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [588/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [589/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [590/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [591/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [592/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [593/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [594/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [595/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [596/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [597/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [598/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [599/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [600/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [601/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [602/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [603/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [604/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [605/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [606/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [607/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [608/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [609/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [610/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [611/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [612/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [613/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [614/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [615/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [616/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [617/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [618/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [619/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [620/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [621/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [622/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [623/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [624/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [625/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [626/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [627/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [628/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [629/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [630/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [631/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [632/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [633/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [634/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [635/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [636/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [637/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [638/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [639/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [640/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [641/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [642/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [643/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [644/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [645/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [646/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [647/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [648/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [649/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [650/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [651/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [652/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [653/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [654/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [655/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [656/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [657/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [658/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [659/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [660/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [661/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [662/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [663/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [664/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [665/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [666/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [667/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [668/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [669/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [670/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [671/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [672/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [673/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [674/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [675/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [676/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [677/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [678/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [679/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [680/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [681/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [682/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [683/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [684/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [685/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [686/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [687/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [688/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [689/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [690/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [691/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [692/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [693/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [694/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [695/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [696/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [697/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [698/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [699/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [700/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [701/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [702/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [703/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [704/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [705/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [706/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [707/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [708/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [709/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [710/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [711/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [712/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [713/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [714/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [715/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [716/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [717/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [718/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [719/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [720/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [721/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [722/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [723/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [724/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [725/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [726/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [727/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [728/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [729/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [730/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [731/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [732/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [733/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [734/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [735/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [736/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [737/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [738/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [739/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [740/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [741/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [742/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [743/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [744/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [745/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [746/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [747/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [748/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [749/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [750/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [751/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [752/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [753/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [754/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [755/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [756/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [757/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [758/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [759/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [760/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [761/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [762/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [763/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [764/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [765/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [766/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [767/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [768/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [769/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [770/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [771/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [772/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [773/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [774/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [775/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [776/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [777/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [778/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [779/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [780/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [781/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [782/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [783/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [784/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [785/1470], Loss: 1.7952\n",
      "Epoch [1/10], Step [786/1470], Loss: 1.7930\n",
      "Epoch [1/10], Step [787/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [788/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [789/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [790/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [791/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [792/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [793/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [794/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [795/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [796/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [797/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [798/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [799/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [800/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [801/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [802/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [803/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [804/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [805/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [806/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [807/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [808/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [809/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [810/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [811/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [812/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [813/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [814/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [815/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [816/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [817/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [818/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [819/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [820/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [821/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [822/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [823/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [824/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [825/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [826/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [827/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [828/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [829/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [830/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [831/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [832/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [833/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [834/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [835/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [836/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [837/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [838/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [839/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [840/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [841/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [842/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [843/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [844/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [845/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [846/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [847/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [848/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [849/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [850/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [851/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [852/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [853/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [854/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [855/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [856/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [857/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [858/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [859/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [860/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [861/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [862/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [863/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [864/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [865/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [866/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [867/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [868/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [869/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [870/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [871/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [872/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [873/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [874/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [875/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [876/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [877/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [878/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [879/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [880/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [881/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [882/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [883/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [884/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [885/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [886/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [887/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [888/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [889/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [890/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [891/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [892/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [893/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [894/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [895/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [896/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [897/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [898/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [899/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [900/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [901/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [902/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [903/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [904/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [905/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [906/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [907/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [908/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [909/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [910/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [911/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [912/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [913/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [914/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [915/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [916/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [917/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [918/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [919/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [920/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [921/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [922/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [923/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [924/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [925/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [926/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [927/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [928/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [929/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [930/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [931/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [932/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [933/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [934/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [935/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [936/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [937/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [938/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [939/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [940/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [941/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [942/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [943/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [944/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [945/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [946/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [947/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [948/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [949/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [950/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [951/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [952/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [953/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [954/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [955/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [956/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [957/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [958/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [959/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [960/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [961/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [962/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [963/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [964/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [965/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [966/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [967/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [968/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [969/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [970/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [971/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [972/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [973/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [974/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [975/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [976/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [977/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [978/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [979/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [980/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [981/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [982/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [983/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [984/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [985/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [986/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [987/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [988/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [989/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [990/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [991/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [992/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [993/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [994/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [995/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [996/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [997/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [998/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [999/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1000/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1001/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1002/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1003/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1004/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1005/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1006/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1007/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1008/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1009/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1010/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1011/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1012/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1013/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1014/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1015/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1016/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1017/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1018/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1019/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1020/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1021/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1022/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1023/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1024/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1025/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1026/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1027/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1028/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1029/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1030/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1031/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1032/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1033/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1034/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1035/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1036/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1037/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1038/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1039/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1040/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1041/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1042/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1043/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1044/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1045/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1046/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1047/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1048/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1049/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1050/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1051/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1052/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1053/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1054/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1055/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1056/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1057/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1058/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1059/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1060/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1061/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1062/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1063/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1064/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1065/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1066/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1067/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1068/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1069/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1070/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1071/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1072/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1073/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1074/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1075/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1076/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1077/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1078/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1079/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1080/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1081/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1082/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1083/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1084/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1085/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1086/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1087/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1088/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1089/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1090/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1091/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1092/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1093/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1094/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1095/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1096/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1097/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1098/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1099/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1100/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1101/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1102/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1103/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1104/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1105/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1106/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1107/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1108/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1109/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1110/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1111/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1112/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1113/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1114/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1115/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1116/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1117/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1118/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1119/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1120/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1121/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1122/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1123/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1124/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1125/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1126/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1127/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1128/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1129/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1130/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1131/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1132/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1133/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1134/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1135/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1136/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1137/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1138/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1139/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1140/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1141/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1142/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1143/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1144/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1145/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1146/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1147/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1148/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1149/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1150/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1151/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1152/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1153/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1154/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1155/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1156/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1157/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1158/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1159/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1160/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1161/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1162/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1163/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1164/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1165/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1166/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1167/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1168/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1169/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1170/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1171/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1172/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1173/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1174/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1175/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1176/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1177/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1178/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1179/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1180/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1181/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1182/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1183/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1184/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1185/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1186/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1187/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1188/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1189/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1190/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1191/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1192/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1193/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1194/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1195/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1196/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1197/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1198/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1199/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1200/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1201/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1202/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1203/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1204/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1205/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1206/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1207/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1208/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1209/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1210/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1211/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1212/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1213/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1214/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1215/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1216/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1217/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1218/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1219/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1220/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1221/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1222/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1223/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1224/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1225/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1226/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1227/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1228/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1229/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1230/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1231/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1232/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1233/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1234/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1235/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1236/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1237/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1238/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1239/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1240/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1241/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1242/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1243/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1244/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1245/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1246/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1247/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1248/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1249/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1250/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1251/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1252/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1253/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1254/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1255/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1256/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1257/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1258/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1259/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1260/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1261/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1262/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1263/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1264/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1265/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1266/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1267/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1268/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1269/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1270/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1271/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1272/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1273/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1274/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1275/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1276/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1277/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1278/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1279/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1280/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1281/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1282/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1283/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1284/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1285/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1286/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1287/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1288/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1289/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1290/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1291/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1292/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1293/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1294/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1295/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1296/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1297/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1298/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1299/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1300/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1301/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1302/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1303/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1304/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1305/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1306/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1307/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1308/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1309/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1310/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1311/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1312/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1313/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1314/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1315/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1316/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1317/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1318/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1319/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1320/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1321/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1322/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1323/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1324/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1325/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1326/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1327/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1328/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1329/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1330/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1331/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1332/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1333/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1334/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1335/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1336/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1337/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1338/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1339/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1340/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1341/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1342/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1343/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1344/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1345/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1346/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1347/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1348/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1349/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1350/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1351/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1352/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1353/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1354/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1355/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1356/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1357/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1358/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1359/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1360/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1361/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1362/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1363/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1364/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1365/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1366/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1367/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1368/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1369/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1370/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1371/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1372/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1373/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1374/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1375/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1376/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1377/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1378/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1379/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1380/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1381/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1382/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1383/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1384/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1385/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1386/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1387/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1388/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1389/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1390/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1391/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1392/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1393/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1394/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1395/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1396/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1397/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1398/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1399/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1400/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1401/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1402/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1403/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1404/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1405/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1406/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1407/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1408/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1409/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1410/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1411/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1412/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1413/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1414/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1415/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1416/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1417/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1418/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1419/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1420/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1421/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1422/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1423/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1424/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1425/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1426/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1427/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1428/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1429/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1430/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1431/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1432/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1433/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1434/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1435/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1436/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1437/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1438/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1439/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1440/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1441/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1442/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1443/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1444/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1445/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1446/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1447/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1448/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1449/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1450/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1451/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1452/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1453/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1454/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1455/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1456/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1457/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1458/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1459/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1460/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1461/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1462/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1463/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1464/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1465/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1466/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1467/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1468/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1469/1470], Loss: 1.7918\n",
      "Epoch [1/10], Step [1470/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [0/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [1/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [2/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [3/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [4/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [5/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [6/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [7/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [8/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [9/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [10/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [11/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [12/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [13/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [14/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [15/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [16/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [17/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [18/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [19/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [20/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [21/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [22/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [23/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [24/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [25/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [26/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [27/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [28/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [29/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [30/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [31/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [32/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [33/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [34/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [35/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [36/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [37/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [38/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [39/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [40/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [41/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [42/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [43/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [44/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [45/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [46/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [47/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [48/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [49/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [50/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [51/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [52/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [53/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [54/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [55/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [56/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [57/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [58/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [59/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [60/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [61/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [62/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [63/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [64/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [65/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [66/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [67/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [68/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [69/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [70/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [71/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [72/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [73/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [74/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [75/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [76/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [77/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [78/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [79/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [80/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [81/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [82/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [83/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [84/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [85/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [86/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [87/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [88/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [89/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [90/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [91/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [92/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [93/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [94/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [95/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [96/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [97/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [98/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [99/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [100/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [101/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [102/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [103/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [104/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [105/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [106/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [107/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [108/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [109/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [110/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [111/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [112/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [113/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [114/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [115/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [116/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [117/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [118/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [119/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [120/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [121/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [122/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [123/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [124/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [125/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [126/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [127/1470], Loss: 1.7918\n",
      "Epoch [2/10], Step [128/1470], Loss: 1.7918\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[111], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, train_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], batch_size):\n\u001b[0;32m      6\u001b[0m         \n\u001b[0;32m      7\u001b[0m         \u001b[38;5;66;03m# Get Input batch and lables\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m[i:i\u001b[38;5;241m+\u001b[39mbatch_size], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m      9\u001b[0m         labels \u001b[38;5;241m=\u001b[39m get_output_tensor(train_labels[i:i\u001b[38;5;241m+\u001b[39mbatch_size])\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;66;03m# forward pass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\cv1\\lib\\site-packages\\pandas\\core\\frame.py:11360\u001b[0m, in \u001b[0;36mDataFrame.values\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m  11286\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m  11287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalues\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m  11288\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  11289\u001b[0m \u001b[38;5;124;03m    Return a Numpy representation of the DataFrame.\u001b[39;00m\n\u001b[0;32m  11290\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  11358\u001b[0m \u001b[38;5;124;03m           ['monkey', nan, None]], dtype=object)\u001b[39;00m\n\u001b[0;32m  11359\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 11360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\cv1\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1732\u001b[0m, in \u001b[0;36mBlockManager.as_array\u001b[1;34m(self, dtype, copy, na_value)\u001b[0m\n\u001b[0;32m   1730\u001b[0m         arr\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mwriteable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   1731\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1732\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interleave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;66;03m# The underlying data was copied within _interleave, so no need\u001b[39;00m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;66;03m# to further copy if copy=True or setting na_value\u001b[39;00m\n\u001b[0;32m   1736\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\cv1\\lib\\site-packages\\pandas\\core\\internals\\managers.py:1794\u001b[0m, in \u001b[0;36mBlockManager._interleave\u001b[1;34m(self, dtype, na_value)\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1793\u001b[0m         arr \u001b[38;5;241m=\u001b[39m blk\u001b[38;5;241m.\u001b[39mget_values(dtype)\n\u001b[1;32m-> 1794\u001b[0m     \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mrl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindexer\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m arr\n\u001b[0;32m   1795\u001b[0m     itemmask[rl\u001b[38;5;241m.\u001b[39mindexer] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1797\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m itemmask\u001b[38;5;241m.\u001b[39mall():\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "# Iterate through number of epochs and determine next step\n",
    "for epoch in range(num_epochs):\n",
    "    for i in range(0, train_data.shape[0], batch_size):\n",
    "        \n",
    "        # Get Input batch and lables\n",
    "        inputs = torch.tensor(train_data.values[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        labels = get_output_tensor(train_labels[i:i+batch_size]).to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss\n",
    "        print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, (i+1)//batch_size, train_data.shape[0]//batch_size, loss.item()))\n",
    "        \n",
    "        # Draw plot of loss\n",
    "        # losses.append(loss.item())\n",
    "        # pl.plot(losses, 'b')\n",
    "        # display.clear_output(wait=True)\n",
    "        # display.display(pl.gcf())\n",
    "      \n",
    "    # Save the model here, in case of interruption or if I'm bored cause my cpu too slow  \n",
    "    torch.save(model.state_dict(), model_path)\n",
    "\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Model\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (fc1): Linear(in_features=562, out_features=100, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=100, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the Model\n",
    "model = MLP(562, 100, 6).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test frames 1-5: 0.0 %\n",
      "Accuracy of the network on test frames 6-10: 0.0 %\n",
      "Accuracy of the network on test frames 11-15: 0.0 %\n",
      "Accuracy of the network on test frames 16-20: 0.0 %\n",
      "Accuracy of the network on test frames 21-25: 0.0 %\n",
      "Accuracy of the network on test frames 26-30: 0.0 %\n",
      "Accuracy of the network on test frames 31-35: 0.0 %\n",
      "Accuracy of the network on test frames 36-40: 0.0 %\n",
      "Accuracy of the network on test frames 41-45: 0.0 %\n",
      "Accuracy of the network on test frames 46-50: 0.0 %\n",
      "Accuracy of the network on test frames 51-55: 0.0 %\n",
      "Accuracy of the network on test frames 56-60: 8.3333 %\n",
      "Accuracy of the network on test frames 61-65: 15.3846 %\n",
      "Accuracy of the network on test frames 66-70: 21.4286 %\n",
      "Accuracy of the network on test frames 71-75: 26.6667 %\n",
      "Accuracy of the network on test frames 76-80: 30.0 %\n",
      "Accuracy of the network on test frames 81-85: 28.2353 %\n",
      "Accuracy of the network on test frames 86-90: 26.6667 %\n",
      "Accuracy of the network on test frames 91-95: 25.2632 %\n",
      "Accuracy of the network on test frames 96-100: 24.0 %\n",
      "Accuracy of the network on test frames 101-105: 22.8571 %\n",
      "Accuracy of the network on test frames 106-110: 21.8182 %\n",
      "Accuracy of the network on test frames 111-115: 20.8696 %\n",
      "Accuracy of the network on test frames 116-120: 20.0 %\n",
      "Accuracy of the network on test frames 121-125: 19.2 %\n",
      "Accuracy of the network on test frames 126-130: 18.4615 %\n",
      "Accuracy of the network on test frames 131-135: 17.7778 %\n",
      "Accuracy of the network on test frames 136-140: 17.1429 %\n",
      "Accuracy of the network on test frames 141-145: 16.5517 %\n",
      "Accuracy of the network on test frames 146-150: 16.0 %\n",
      "Accuracy of the network on test frames 151-155: 15.4839 %\n",
      "Accuracy of the network on test frames 156-160: 15.0 %\n",
      "Accuracy of the network on test frames 161-165: 14.5455 %\n",
      "Accuracy of the network on test frames 166-170: 14.1176 %\n",
      "Accuracy of the network on test frames 171-175: 13.7143 %\n",
      "Accuracy of the network on test frames 176-180: 13.3333 %\n",
      "Accuracy of the network on test frames 181-185: 12.973 %\n",
      "Accuracy of the network on test frames 186-190: 12.6316 %\n",
      "Accuracy of the network on test frames 191-195: 12.3077 %\n",
      "Accuracy of the network on test frames 196-200: 12.0 %\n",
      "Accuracy of the network on test frames 201-205: 12.6829 %\n",
      "Accuracy of the network on test frames 206-210: 14.7619 %\n",
      "Accuracy of the network on test frames 211-215: 16.7442 %\n",
      "Accuracy of the network on test frames 216-220: 18.6364 %\n",
      "Accuracy of the network on test frames 221-225: 20.4444 %\n",
      "Accuracy of the network on test frames 226-230: 20.8696 %\n",
      "Accuracy of the network on test frames 231-235: 20.4255 %\n",
      "Accuracy of the network on test frames 236-240: 20.0 %\n",
      "Accuracy of the network on test frames 241-245: 19.5918 %\n",
      "Accuracy of the network on test frames 246-250: 19.2 %\n",
      "Accuracy of the network on test frames 251-255: 18.8235 %\n",
      "Accuracy of the network on test frames 256-260: 18.4615 %\n",
      "Accuracy of the network on test frames 261-265: 18.1132 %\n",
      "Accuracy of the network on test frames 266-270: 17.7778 %\n",
      "Accuracy of the network on test frames 271-275: 17.4545 %\n",
      "Accuracy of the network on test frames 276-280: 17.1429 %\n",
      "Accuracy of the network on test frames 281-285: 16.8421 %\n",
      "Accuracy of the network on test frames 286-290: 16.5517 %\n",
      "Accuracy of the network on test frames 291-295: 16.2712 %\n",
      "Accuracy of the network on test frames 296-300: 16.0 %\n",
      "Accuracy of the network on test frames 301-305: 15.7377 %\n",
      "Accuracy of the network on test frames 306-310: 15.4839 %\n",
      "Accuracy of the network on test frames 311-315: 15.2381 %\n",
      "Accuracy of the network on test frames 316-320: 15.0 %\n",
      "Accuracy of the network on test frames 321-325: 14.7692 %\n",
      "Accuracy of the network on test frames 326-330: 14.5455 %\n",
      "Accuracy of the network on test frames 331-335: 14.3284 %\n",
      "Accuracy of the network on test frames 336-340: 14.1176 %\n",
      "Accuracy of the network on test frames 341-345: 13.913 %\n",
      "Accuracy of the network on test frames 346-350: 13.7143 %\n",
      "Accuracy of the network on test frames 351-355: 13.8028 %\n",
      "Accuracy of the network on test frames 356-360: 15.0 %\n",
      "Accuracy of the network on test frames 361-365: 16.1644 %\n",
      "Accuracy of the network on test frames 366-370: 17.2973 %\n",
      "Accuracy of the network on test frames 371-375: 18.4 %\n",
      "Accuracy of the network on test frames 376-380: 19.4737 %\n",
      "Accuracy of the network on test frames 381-385: 20.2597 %\n",
      "Accuracy of the network on test frames 386-390: 20.0 %\n",
      "Accuracy of the network on test frames 391-395: 19.7468 %\n",
      "Accuracy of the network on test frames 396-400: 19.5 %\n",
      "Accuracy of the network on test frames 401-405: 19.2593 %\n",
      "Accuracy of the network on test frames 406-410: 19.0244 %\n",
      "Accuracy of the network on test frames 411-415: 18.7952 %\n",
      "Accuracy of the network on test frames 416-420: 18.5714 %\n",
      "Accuracy of the network on test frames 421-425: 18.3529 %\n",
      "Accuracy of the network on test frames 426-430: 18.1395 %\n",
      "Accuracy of the network on test frames 431-435: 17.931 %\n",
      "Accuracy of the network on test frames 436-440: 17.7273 %\n",
      "Accuracy of the network on test frames 441-445: 17.5281 %\n",
      "Accuracy of the network on test frames 446-450: 17.3333 %\n",
      "Accuracy of the network on test frames 451-455: 17.1429 %\n",
      "Accuracy of the network on test frames 456-460: 16.9565 %\n",
      "Accuracy of the network on test frames 461-465: 16.7742 %\n",
      "Accuracy of the network on test frames 466-470: 16.5957 %\n",
      "Accuracy of the network on test frames 471-475: 16.4211 %\n",
      "Accuracy of the network on test frames 476-480: 16.25 %\n",
      "Accuracy of the network on test frames 481-485: 16.0825 %\n",
      "Accuracy of the network on test frames 486-490: 15.9184 %\n",
      "Accuracy of the network on test frames 491-495: 15.7576 %\n",
      "Accuracy of the network on test frames 496-500: 15.6 %\n",
      "Accuracy of the network on test frames 501-505: 15.4455 %\n",
      "Accuracy of the network on test frames 506-510: 15.2941 %\n",
      "Accuracy of the network on test frames 511-515: 15.1456 %\n",
      "Accuracy of the network on test frames 516-520: 15.0 %\n",
      "Accuracy of the network on test frames 521-525: 15.8095 %\n",
      "Accuracy of the network on test frames 526-530: 16.6038 %\n",
      "Accuracy of the network on test frames 531-535: 17.3832 %\n",
      "Accuracy of the network on test frames 536-540: 18.1481 %\n",
      "Accuracy of the network on test frames 541-545: 18.7156 %\n",
      "Accuracy of the network on test frames 546-550: 18.5455 %\n",
      "Accuracy of the network on test frames 551-555: 18.3784 %\n",
      "Accuracy of the network on test frames 556-560: 18.2143 %\n",
      "Accuracy of the network on test frames 561-565: 18.0531 %\n",
      "Accuracy of the network on test frames 566-570: 17.8947 %\n",
      "Accuracy of the network on test frames 571-575: 17.7391 %\n",
      "Accuracy of the network on test frames 576-580: 17.5862 %\n",
      "Accuracy of the network on test frames 581-585: 17.4359 %\n",
      "Accuracy of the network on test frames 586-590: 17.2881 %\n",
      "Accuracy of the network on test frames 591-595: 17.1429 %\n",
      "Accuracy of the network on test frames 596-600: 17.0 %\n",
      "Accuracy of the network on test frames 601-605: 16.8595 %\n",
      "Accuracy of the network on test frames 606-610: 16.7213 %\n",
      "Accuracy of the network on test frames 611-615: 16.5854 %\n",
      "Accuracy of the network on test frames 616-620: 16.4516 %\n",
      "Accuracy of the network on test frames 621-625: 16.32 %\n",
      "Accuracy of the network on test frames 626-630: 16.1905 %\n",
      "Accuracy of the network on test frames 631-635: 16.063 %\n",
      "Accuracy of the network on test frames 636-640: 15.9375 %\n",
      "Accuracy of the network on test frames 641-645: 15.814 %\n",
      "Accuracy of the network on test frames 646-650: 15.6923 %\n",
      "Accuracy of the network on test frames 651-655: 15.5725 %\n",
      "Accuracy of the network on test frames 656-660: 15.4545 %\n",
      "Accuracy of the network on test frames 661-665: 15.3383 %\n",
      "Accuracy of the network on test frames 666-670: 15.8209 %\n",
      "Accuracy of the network on test frames 671-675: 16.4444 %\n",
      "Accuracy of the network on test frames 676-680: 17.0588 %\n",
      "Accuracy of the network on test frames 681-685: 17.6642 %\n",
      "Accuracy of the network on test frames 686-690: 18.2609 %\n",
      "Accuracy of the network on test frames 691-695: 18.1295 %\n",
      "Accuracy of the network on test frames 696-700: 18.0 %\n",
      "Accuracy of the network on test frames 701-705: 17.8723 %\n",
      "Accuracy of the network on test frames 706-710: 17.7465 %\n",
      "Accuracy of the network on test frames 711-715: 17.6224 %\n",
      "Accuracy of the network on test frames 716-720: 17.5 %\n",
      "Accuracy of the network on test frames 721-725: 17.3793 %\n",
      "Accuracy of the network on test frames 726-730: 17.2603 %\n",
      "Accuracy of the network on test frames 731-735: 17.1429 %\n",
      "Accuracy of the network on test frames 736-740: 17.027 %\n",
      "Accuracy of the network on test frames 741-745: 16.9128 %\n",
      "Accuracy of the network on test frames 746-750: 16.8 %\n",
      "Accuracy of the network on test frames 751-755: 16.6887 %\n",
      "Accuracy of the network on test frames 756-760: 16.5789 %\n",
      "Accuracy of the network on test frames 761-765: 16.4706 %\n",
      "Accuracy of the network on test frames 766-770: 16.3636 %\n",
      "Accuracy of the network on test frames 771-775: 16.2581 %\n",
      "Accuracy of the network on test frames 776-780: 16.1538 %\n",
      "Accuracy of the network on test frames 781-785: 16.051 %\n",
      "Accuracy of the network on test frames 786-790: 15.9494 %\n",
      "Accuracy of the network on test frames 791-795: 15.8491 %\n",
      "Accuracy of the network on test frames 796-800: 15.75 %\n",
      "Accuracy of the network on test frames 801-805: 15.6522 %\n",
      "Accuracy of the network on test frames 806-810: 15.5556 %\n",
      "Accuracy of the network on test frames 811-815: 15.9509 %\n",
      "Accuracy of the network on test frames 816-820: 16.4634 %\n",
      "Accuracy of the network on test frames 821-825: 16.9697 %\n",
      "Accuracy of the network on test frames 826-830: 17.4699 %\n",
      "Accuracy of the network on test frames 831-835: 17.9641 %\n",
      "Accuracy of the network on test frames 836-840: 18.0952 %\n",
      "Accuracy of the network on test frames 841-845: 17.9882 %\n",
      "Accuracy of the network on test frames 846-850: 17.8824 %\n",
      "Accuracy of the network on test frames 851-855: 17.7778 %\n",
      "Accuracy of the network on test frames 856-860: 17.6744 %\n",
      "Accuracy of the network on test frames 861-865: 17.5723 %\n",
      "Accuracy of the network on test frames 866-870: 17.4713 %\n",
      "Accuracy of the network on test frames 871-875: 17.3714 %\n",
      "Accuracy of the network on test frames 876-880: 17.2727 %\n",
      "Accuracy of the network on test frames 881-885: 17.1751 %\n",
      "Accuracy of the network on test frames 886-890: 17.0787 %\n",
      "Accuracy of the network on test frames 891-895: 16.9832 %\n",
      "Accuracy of the network on test frames 896-900: 16.8889 %\n",
      "Accuracy of the network on test frames 901-905: 16.7956 %\n",
      "Accuracy of the network on test frames 906-910: 16.7033 %\n",
      "Accuracy of the network on test frames 911-915: 16.612 %\n",
      "Accuracy of the network on test frames 916-920: 16.5217 %\n",
      "Accuracy of the network on test frames 921-925: 16.4324 %\n",
      "Accuracy of the network on test frames 926-930: 16.3441 %\n",
      "Accuracy of the network on test frames 931-935: 16.2567 %\n",
      "Accuracy of the network on test frames 936-940: 16.1702 %\n",
      "Accuracy of the network on test frames 941-945: 16.0847 %\n",
      "Accuracy of the network on test frames 946-950: 16.0 %\n",
      "Accuracy of the network on test frames 951-955: 16.0209 %\n",
      "Accuracy of the network on test frames 956-960: 16.4583 %\n",
      "Accuracy of the network on test frames 961-965: 16.8912 %\n",
      "Accuracy of the network on test frames 966-970: 17.3196 %\n",
      "Accuracy of the network on test frames 971-975: 17.7436 %\n",
      "Accuracy of the network on test frames 976-980: 18.1633 %\n",
      "Accuracy of the network on test frames 981-985: 18.5787 %\n",
      "Accuracy of the network on test frames 986-990: 18.4848 %\n",
      "Accuracy of the network on test frames 991-995: 18.392 %\n",
      "Accuracy of the network on test frames 996-1000: 18.3 %\n",
      "Accuracy of the network on test frames 1001-1005: 18.209 %\n",
      "Accuracy of the network on test frames 1006-1010: 18.1188 %\n",
      "Accuracy of the network on test frames 1011-1015: 18.0296 %\n",
      "Accuracy of the network on test frames 1016-1020: 17.9412 %\n",
      "Accuracy of the network on test frames 1021-1025: 17.8537 %\n",
      "Accuracy of the network on test frames 1026-1030: 17.767 %\n",
      "Accuracy of the network on test frames 1031-1035: 17.6812 %\n",
      "Accuracy of the network on test frames 1036-1040: 17.5962 %\n",
      "Accuracy of the network on test frames 1041-1045: 17.512 %\n",
      "Accuracy of the network on test frames 1046-1050: 17.4286 %\n",
      "Accuracy of the network on test frames 1051-1055: 17.346 %\n",
      "Accuracy of the network on test frames 1056-1060: 17.2642 %\n",
      "Accuracy of the network on test frames 1061-1065: 17.1831 %\n",
      "Accuracy of the network on test frames 1066-1070: 17.1028 %\n",
      "Accuracy of the network on test frames 1071-1075: 17.0233 %\n",
      "Accuracy of the network on test frames 1076-1080: 16.9444 %\n",
      "Accuracy of the network on test frames 1081-1085: 16.8664 %\n",
      "Accuracy of the network on test frames 1086-1090: 16.789 %\n",
      "Accuracy of the network on test frames 1091-1095: 16.7123 %\n",
      "Accuracy of the network on test frames 1096-1100: 16.6364 %\n",
      "Accuracy of the network on test frames 1101-1105: 16.5611 %\n",
      "Accuracy of the network on test frames 1106-1110: 16.9369 %\n",
      "Accuracy of the network on test frames 1111-1115: 17.3094 %\n",
      "Accuracy of the network on test frames 1116-1120: 17.6786 %\n",
      "Accuracy of the network on test frames 1121-1125: 18.0444 %\n",
      "Accuracy of the network on test frames 1126-1130: 18.4071 %\n",
      "Accuracy of the network on test frames 1131-1135: 18.5022 %\n",
      "Accuracy of the network on test frames 1136-1140: 18.4211 %\n",
      "Accuracy of the network on test frames 1141-1145: 18.3406 %\n",
      "Accuracy of the network on test frames 1146-1150: 18.2609 %\n",
      "Accuracy of the network on test frames 1151-1155: 18.1818 %\n",
      "Accuracy of the network on test frames 1156-1160: 18.1034 %\n",
      "Accuracy of the network on test frames 1161-1165: 18.0258 %\n",
      "Accuracy of the network on test frames 1166-1170: 17.9487 %\n",
      "Accuracy of the network on test frames 1171-1175: 17.8723 %\n",
      "Accuracy of the network on test frames 1176-1180: 17.7966 %\n",
      "Accuracy of the network on test frames 1181-1185: 17.7215 %\n",
      "Accuracy of the network on test frames 1186-1190: 17.6471 %\n",
      "Accuracy of the network on test frames 1191-1195: 17.5732 %\n",
      "Accuracy of the network on test frames 1196-1200: 17.5 %\n",
      "Accuracy of the network on test frames 1201-1205: 17.4274 %\n",
      "Accuracy of the network on test frames 1206-1210: 17.3554 %\n",
      "Accuracy of the network on test frames 1211-1215: 17.284 %\n",
      "Accuracy of the network on test frames 1216-1220: 17.2131 %\n",
      "Accuracy of the network on test frames 1221-1225: 17.1429 %\n",
      "Accuracy of the network on test frames 1226-1230: 17.0732 %\n",
      "Accuracy of the network on test frames 1231-1235: 17.004 %\n",
      "Accuracy of the network on test frames 1236-1240: 16.9355 %\n",
      "Accuracy of the network on test frames 1241-1245: 16.8675 %\n",
      "Accuracy of the network on test frames 1246-1250: 16.8 %\n",
      "Accuracy of the network on test frames 1251-1255: 16.7331 %\n",
      "Accuracy of the network on test frames 1256-1260: 16.9841 %\n",
      "Accuracy of the network on test frames 1261-1265: 17.3123 %\n",
      "Accuracy of the network on test frames 1266-1270: 17.6378 %\n",
      "Accuracy of the network on test frames 1271-1275: 17.9608 %\n",
      "Accuracy of the network on test frames 1276-1280: 18.2812 %\n",
      "Accuracy of the network on test frames 1281-1285: 18.4436 %\n",
      "Accuracy of the network on test frames 1286-1290: 18.3721 %\n",
      "Accuracy of the network on test frames 1291-1295: 18.3012 %\n",
      "Accuracy of the network on test frames 1296-1300: 18.2308 %\n",
      "Accuracy of the network on test frames 1301-1305: 18.1609 %\n",
      "Accuracy of the network on test frames 1306-1310: 18.0916 %\n",
      "Accuracy of the network on test frames 1311-1315: 18.0228 %\n",
      "Accuracy of the network on test frames 1316-1320: 17.9545 %\n",
      "Accuracy of the network on test frames 1321-1325: 17.8868 %\n",
      "Accuracy of the network on test frames 1326-1330: 17.8195 %\n",
      "Accuracy of the network on test frames 1331-1335: 17.7528 %\n",
      "Accuracy of the network on test frames 1336-1340: 17.6866 %\n",
      "Accuracy of the network on test frames 1341-1345: 17.6208 %\n",
      "Accuracy of the network on test frames 1346-1350: 17.5556 %\n",
      "Accuracy of the network on test frames 1351-1355: 17.4908 %\n",
      "Accuracy of the network on test frames 1356-1360: 17.4265 %\n",
      "Accuracy of the network on test frames 1361-1365: 17.3626 %\n",
      "Accuracy of the network on test frames 1366-1370: 17.2993 %\n",
      "Accuracy of the network on test frames 1371-1375: 17.2364 %\n",
      "Accuracy of the network on test frames 1376-1380: 17.1739 %\n",
      "Accuracy of the network on test frames 1381-1385: 17.1119 %\n",
      "Accuracy of the network on test frames 1386-1390: 17.0504 %\n",
      "Accuracy of the network on test frames 1391-1395: 16.9892 %\n",
      "Accuracy of the network on test frames 1396-1400: 16.9286 %\n",
      "Accuracy of the network on test frames 1401-1405: 16.8683 %\n",
      "Accuracy of the network on test frames 1406-1410: 16.8085 %\n",
      "Accuracy of the network on test frames 1411-1415: 16.7491 %\n",
      "Accuracy of the network on test frames 1416-1420: 16.7606 %\n",
      "Accuracy of the network on test frames 1421-1425: 17.0526 %\n",
      "Accuracy of the network on test frames 1426-1430: 17.3427 %\n",
      "Accuracy of the network on test frames 1431-1435: 17.6307 %\n",
      "Accuracy of the network on test frames 1436-1440: 17.9167 %\n",
      "Accuracy of the network on test frames 1441-1445: 18.2007 %\n",
      "Accuracy of the network on test frames 1446-1450: 18.4828 %\n",
      "Accuracy of the network on test frames 1451-1455: 18.5567 %\n",
      "Accuracy of the network on test frames 1456-1460: 18.4932 %\n",
      "Accuracy of the network on test frames 1461-1465: 18.43 %\n",
      "Accuracy of the network on test frames 1466-1470: 18.3673 %\n",
      "Accuracy of the network on test frames 1471-1475: 18.3051 %\n",
      "Accuracy of the network on test frames 1476-1480: 18.2432 %\n",
      "Accuracy of the network on test frames 1481-1485: 18.1818 %\n",
      "Accuracy of the network on test frames 1486-1490: 18.1208 %\n",
      "Accuracy of the network on test frames 1491-1495: 18.0602 %\n",
      "Accuracy of the network on test frames 1496-1500: 18.0 %\n",
      "Accuracy of the network on test frames 1501-1505: 17.9402 %\n",
      "Accuracy of the network on test frames 1506-1510: 17.8808 %\n",
      "Accuracy of the network on test frames 1511-1515: 17.8218 %\n",
      "Accuracy of the network on test frames 1516-1520: 17.7632 %\n",
      "Accuracy of the network on test frames 1521-1525: 17.7049 %\n",
      "Accuracy of the network on test frames 1526-1530: 17.6471 %\n",
      "Accuracy of the network on test frames 1531-1535: 17.5896 %\n",
      "Accuracy of the network on test frames 1536-1540: 17.5325 %\n",
      "Accuracy of the network on test frames 1541-1545: 17.4757 %\n",
      "Accuracy of the network on test frames 1546-1550: 17.4194 %\n",
      "Accuracy of the network on test frames 1551-1555: 17.3633 %\n",
      "Accuracy of the network on test frames 1556-1560: 17.3077 %\n",
      "Accuracy of the network on test frames 1561-1565: 17.2524 %\n",
      "Accuracy of the network on test frames 1566-1570: 17.1975 %\n",
      "Accuracy of the network on test frames 1571-1575: 17.3333 %\n",
      "Accuracy of the network on test frames 1576-1580: 17.5949 %\n",
      "Accuracy of the network on test frames 1581-1585: 17.8549 %\n",
      "Accuracy of the network on test frames 1586-1590: 18.1132 %\n",
      "Accuracy of the network on test frames 1591-1595: 18.3699 %\n",
      "Accuracy of the network on test frames 1596-1600: 18.625 %\n",
      "Accuracy of the network on test frames 1601-1605: 18.8785 %\n",
      "Accuracy of the network on test frames 1606-1610: 18.8199 %\n",
      "Accuracy of the network on test frames 1611-1615: 18.7616 %\n",
      "Accuracy of the network on test frames 1616-1620: 18.7037 %\n",
      "Accuracy of the network on test frames 1621-1625: 18.6462 %\n",
      "Accuracy of the network on test frames 1626-1630: 18.589 %\n",
      "Accuracy of the network on test frames 1631-1635: 18.5321 %\n",
      "Accuracy of the network on test frames 1636-1640: 18.4756 %\n",
      "Accuracy of the network on test frames 1641-1645: 18.4195 %\n",
      "Accuracy of the network on test frames 1646-1650: 18.3636 %\n",
      "Accuracy of the network on test frames 1651-1655: 18.3082 %\n",
      "Accuracy of the network on test frames 1656-1660: 18.253 %\n",
      "Accuracy of the network on test frames 1661-1665: 18.1982 %\n",
      "Accuracy of the network on test frames 1666-1670: 18.1437 %\n",
      "Accuracy of the network on test frames 1671-1675: 18.0896 %\n",
      "Accuracy of the network on test frames 1676-1680: 18.0357 %\n",
      "Accuracy of the network on test frames 1681-1685: 17.9822 %\n",
      "Accuracy of the network on test frames 1686-1690: 17.929 %\n",
      "Accuracy of the network on test frames 1691-1695: 17.8761 %\n",
      "Accuracy of the network on test frames 1696-1700: 17.8235 %\n",
      "Accuracy of the network on test frames 1701-1705: 17.7713 %\n",
      "Accuracy of the network on test frames 1706-1710: 17.7193 %\n",
      "Accuracy of the network on test frames 1711-1715: 17.6676 %\n",
      "Accuracy of the network on test frames 1716-1720: 17.6163 %\n",
      "Accuracy of the network on test frames 1721-1725: 17.5652 %\n",
      "Accuracy of the network on test frames 1726-1730: 17.5145 %\n",
      "Accuracy of the network on test frames 1731-1735: 17.464 %\n",
      "Accuracy of the network on test frames 1736-1740: 17.4138 %\n",
      "Accuracy of the network on test frames 1741-1745: 17.3639 %\n",
      "Accuracy of the network on test frames 1746-1750: 17.4286 %\n",
      "Accuracy of the network on test frames 1751-1755: 17.6638 %\n",
      "Accuracy of the network on test frames 1756-1760: 17.8977 %\n",
      "Accuracy of the network on test frames 1761-1765: 18.1303 %\n",
      "Accuracy of the network on test frames 1766-1770: 18.3616 %\n",
      "Accuracy of the network on test frames 1771-1775: 18.5915 %\n",
      "Accuracy of the network on test frames 1776-1780: 18.6517 %\n",
      "Accuracy of the network on test frames 1781-1785: 18.5994 %\n",
      "Accuracy of the network on test frames 1786-1790: 18.5475 %\n",
      "Accuracy of the network on test frames 1791-1795: 18.4958 %\n",
      "Accuracy of the network on test frames 1796-1800: 18.4444 %\n",
      "Accuracy of the network on test frames 1801-1805: 18.3934 %\n",
      "Accuracy of the network on test frames 1806-1810: 18.3425 %\n",
      "Accuracy of the network on test frames 1811-1815: 18.292 %\n",
      "Accuracy of the network on test frames 1816-1820: 18.2418 %\n",
      "Accuracy of the network on test frames 1821-1825: 18.1918 %\n",
      "Accuracy of the network on test frames 1826-1830: 18.1421 %\n",
      "Accuracy of the network on test frames 1831-1835: 18.0926 %\n",
      "Accuracy of the network on test frames 1836-1840: 18.0435 %\n",
      "Accuracy of the network on test frames 1841-1845: 17.9946 %\n",
      "Accuracy of the network on test frames 1846-1850: 17.9459 %\n",
      "Accuracy of the network on test frames 1851-1855: 17.8976 %\n",
      "Accuracy of the network on test frames 1856-1860: 17.8495 %\n",
      "Accuracy of the network on test frames 1861-1865: 17.8016 %\n",
      "Accuracy of the network on test frames 1866-1870: 17.754 %\n",
      "Accuracy of the network on test frames 1871-1875: 17.7067 %\n",
      "Accuracy of the network on test frames 1876-1880: 17.6596 %\n",
      "Accuracy of the network on test frames 1881-1885: 17.6127 %\n",
      "Accuracy of the network on test frames 1886-1890: 17.5661 %\n",
      "Accuracy of the network on test frames 1891-1895: 17.5198 %\n",
      "Accuracy of the network on test frames 1896-1900: 17.4737 %\n",
      "Accuracy of the network on test frames 1901-1905: 17.4278 %\n",
      "Accuracy of the network on test frames 1906-1910: 17.3822 %\n",
      "Accuracy of the network on test frames 1911-1915: 17.3368 %\n",
      "Accuracy of the network on test frames 1916-1920: 17.3958 %\n",
      "Accuracy of the network on test frames 1921-1925: 17.6104 %\n",
      "Accuracy of the network on test frames 1926-1930: 17.8238 %\n",
      "Accuracy of the network on test frames 1931-1935: 18.0362 %\n",
      "Accuracy of the network on test frames 1936-1940: 18.2474 %\n",
      "Accuracy of the network on test frames 1941-1945: 18.4576 %\n",
      "Accuracy of the network on test frames 1946-1950: 18.6667 %\n",
      "Accuracy of the network on test frames 1951-1955: 18.6189 %\n",
      "Accuracy of the network on test frames 1956-1960: 18.5714 %\n",
      "Accuracy of the network on test frames 1961-1965: 18.5242 %\n",
      "Accuracy of the network on test frames 1966-1970: 18.4772 %\n",
      "Accuracy of the network on test frames 1971-1975: 18.4304 %\n",
      "Accuracy of the network on test frames 1976-1980: 18.3838 %\n",
      "Accuracy of the network on test frames 1981-1985: 18.3375 %\n",
      "Accuracy of the network on test frames 1986-1990: 18.2915 %\n",
      "Accuracy of the network on test frames 1991-1995: 18.2456 %\n",
      "Accuracy of the network on test frames 1996-2000: 18.2 %\n",
      "Accuracy of the network on test frames 2001-2005: 18.1546 %\n",
      "Accuracy of the network on test frames 2006-2010: 18.1095 %\n",
      "Accuracy of the network on test frames 2011-2015: 18.0645 %\n",
      "Accuracy of the network on test frames 2016-2020: 18.0198 %\n",
      "Accuracy of the network on test frames 2021-2025: 17.9753 %\n",
      "Accuracy of the network on test frames 2026-2030: 17.931 %\n",
      "Accuracy of the network on test frames 2031-2035: 17.887 %\n",
      "Accuracy of the network on test frames 2036-2040: 17.8431 %\n",
      "Accuracy of the network on test frames 2041-2045: 17.7995 %\n",
      "Accuracy of the network on test frames 2046-2050: 17.7561 %\n",
      "Accuracy of the network on test frames 2051-2055: 17.7129 %\n",
      "Accuracy of the network on test frames 2056-2060: 17.6699 %\n",
      "Accuracy of the network on test frames 2061-2065: 17.6271 %\n",
      "Accuracy of the network on test frames 2066-2070: 17.5845 %\n",
      "Accuracy of the network on test frames 2071-2075: 17.5422 %\n",
      "Accuracy of the network on test frames 2076-2080: 17.5 %\n",
      "Accuracy of the network on test frames 2081-2085: 17.458 %\n",
      "Accuracy of the network on test frames 2086-2090: 17.4163 %\n",
      "Accuracy of the network on test frames 2091-2095: 17.3747 %\n",
      "Accuracy of the network on test frames 2096-2100: 17.5238 %\n",
      "Accuracy of the network on test frames 2101-2105: 17.7197 %\n",
      "Accuracy of the network on test frames 2106-2110: 17.9147 %\n",
      "Accuracy of the network on test frames 2111-2115: 18.1087 %\n",
      "Accuracy of the network on test frames 2116-2120: 18.3019 %\n",
      "Accuracy of the network on test frames 2121-2125: 18.4941 %\n",
      "Accuracy of the network on test frames 2126-2130: 18.6385 %\n",
      "Accuracy of the network on test frames 2131-2135: 18.5948 %\n",
      "Accuracy of the network on test frames 2136-2140: 18.5514 %\n",
      "Accuracy of the network on test frames 2141-2145: 18.5082 %\n",
      "Accuracy of the network on test frames 2146-2150: 18.4651 %\n",
      "Accuracy of the network on test frames 2151-2155: 18.4223 %\n",
      "Accuracy of the network on test frames 2156-2160: 18.3796 %\n",
      "Accuracy of the network on test frames 2161-2165: 18.3372 %\n",
      "Accuracy of the network on test frames 2166-2170: 18.2949 %\n",
      "Accuracy of the network on test frames 2171-2175: 18.2529 %\n",
      "Accuracy of the network on test frames 2176-2180: 18.211 %\n",
      "Accuracy of the network on test frames 2181-2185: 18.1693 %\n",
      "Accuracy of the network on test frames 2186-2190: 18.1279 %\n",
      "Accuracy of the network on test frames 2191-2195: 18.0866 %\n",
      "Accuracy of the network on test frames 2196-2200: 18.0455 %\n",
      "Accuracy of the network on test frames 2201-2205: 18.0045 %\n",
      "Accuracy of the network on test frames 2206-2210: 17.9638 %\n",
      "Accuracy of the network on test frames 2211-2215: 17.9233 %\n",
      "Accuracy of the network on test frames 2216-2220: 17.8829 %\n",
      "Accuracy of the network on test frames 2221-2225: 17.8427 %\n",
      "Accuracy of the network on test frames 2226-2230: 17.8027 %\n",
      "Accuracy of the network on test frames 2231-2235: 17.7629 %\n",
      "Accuracy of the network on test frames 2236-2240: 17.7232 %\n",
      "Accuracy of the network on test frames 2241-2245: 17.6837 %\n",
      "Accuracy of the network on test frames 2246-2250: 17.6444 %\n",
      "Accuracy of the network on test frames 2251-2255: 17.6053 %\n",
      "Accuracy of the network on test frames 2256-2260: 17.5664 %\n",
      "Accuracy of the network on test frames 2261-2265: 17.5276 %\n",
      "Accuracy of the network on test frames 2266-2270: 17.489 %\n",
      "Accuracy of the network on test frames 2271-2275: 17.4505 %\n",
      "Accuracy of the network on test frames 2276-2280: 17.4123 %\n",
      "Accuracy of the network on test frames 2281-2285: 17.3742 %\n",
      "Accuracy of the network on test frames 2286-2290: 17.5109 %\n",
      "Accuracy of the network on test frames 2291-2295: 17.6906 %\n",
      "Accuracy of the network on test frames 2296-2300: 17.8696 %\n",
      "Accuracy of the network on test frames 2301-2305: 18.0477 %\n",
      "Accuracy of the network on test frames 2306-2310: 18.2251 %\n",
      "Accuracy of the network on test frames 2311-2315: 18.4017 %\n",
      "Accuracy of the network on test frames 2316-2320: 18.4483 %\n",
      "Accuracy of the network on test frames 2321-2325: 18.4086 %\n",
      "Accuracy of the network on test frames 2326-2330: 18.3691 %\n",
      "Accuracy of the network on test frames 2331-2335: 18.3298 %\n",
      "Accuracy of the network on test frames 2336-2340: 18.2906 %\n",
      "Accuracy of the network on test frames 2341-2345: 18.2516 %\n",
      "Accuracy of the network on test frames 2346-2350: 18.2128 %\n",
      "Accuracy of the network on test frames 2351-2355: 18.1741 %\n",
      "Accuracy of the network on test frames 2356-2360: 18.1356 %\n",
      "Accuracy of the network on test frames 2361-2365: 18.0973 %\n",
      "Accuracy of the network on test frames 2366-2370: 18.0591 %\n",
      "Accuracy of the network on test frames 2371-2375: 18.0211 %\n",
      "Accuracy of the network on test frames 2376-2380: 17.9832 %\n",
      "Accuracy of the network on test frames 2381-2385: 17.9455 %\n",
      "Accuracy of the network on test frames 2386-2390: 17.9079 %\n",
      "Accuracy of the network on test frames 2391-2395: 17.8706 %\n",
      "Accuracy of the network on test frames 2396-2400: 17.8333 %\n",
      "Accuracy of the network on test frames 2401-2405: 17.7963 %\n",
      "Accuracy of the network on test frames 2406-2410: 17.7593 %\n",
      "Accuracy of the network on test frames 2411-2415: 17.7226 %\n",
      "Accuracy of the network on test frames 2416-2420: 17.686 %\n",
      "Accuracy of the network on test frames 2421-2425: 17.6495 %\n",
      "Accuracy of the network on test frames 2426-2430: 17.6132 %\n",
      "Accuracy of the network on test frames 2431-2435: 17.577 %\n",
      "Accuracy of the network on test frames 2436-2440: 17.541 %\n",
      "Accuracy of the network on test frames 2441-2445: 17.5051 %\n",
      "Accuracy of the network on test frames 2446-2450: 17.4694 %\n",
      "Accuracy of the network on test frames 2451-2455: 17.4338 %\n",
      "Accuracy of the network on test frames 2456-2460: 17.5203 %\n",
      "Accuracy of the network on test frames 2461-2465: 17.6876 %\n",
      "Accuracy of the network on test frames 2466-2470: 17.8543 %\n",
      "Accuracy of the network on test frames 2471-2475: 18.0202 %\n",
      "Accuracy of the network on test frames 2476-2480: 18.1855 %\n",
      "Accuracy of the network on test frames 2481-2485: 18.3501 %\n",
      "Accuracy of the network on test frames 2486-2490: 18.5141 %\n",
      "Accuracy of the network on test frames 2491-2495: 18.6373 %\n",
      "Accuracy of the network on test frames 2496-2500: 18.6 %\n",
      "Accuracy of the network on test frames 2501-2505: 18.5629 %\n",
      "Accuracy of the network on test frames 2506-2510: 18.5259 %\n",
      "Accuracy of the network on test frames 2511-2515: 18.4891 %\n",
      "Accuracy of the network on test frames 2516-2520: 18.4524 %\n",
      "Accuracy of the network on test frames 2521-2525: 18.4158 %\n",
      "Accuracy of the network on test frames 2526-2530: 18.3794 %\n",
      "Accuracy of the network on test frames 2531-2535: 18.3432 %\n",
      "Accuracy of the network on test frames 2536-2540: 18.3071 %\n",
      "Accuracy of the network on test frames 2541-2545: 18.2711 %\n",
      "Accuracy of the network on test frames 2546-2550: 18.2353 %\n",
      "Accuracy of the network on test frames 2551-2555: 18.1996 %\n",
      "Accuracy of the network on test frames 2556-2560: 18.1641 %\n",
      "Accuracy of the network on test frames 2561-2565: 18.1287 %\n",
      "Accuracy of the network on test frames 2566-2570: 18.0934 %\n",
      "Accuracy of the network on test frames 2571-2575: 18.0583 %\n",
      "Accuracy of the network on test frames 2576-2580: 18.0233 %\n",
      "Accuracy of the network on test frames 2581-2585: 17.9884 %\n",
      "Accuracy of the network on test frames 2586-2590: 17.9537 %\n",
      "Accuracy of the network on test frames 2591-2595: 17.9191 %\n",
      "Accuracy of the network on test frames 2596-2600: 17.8846 %\n",
      "Accuracy of the network on test frames 2601-2605: 17.8503 %\n",
      "Accuracy of the network on test frames 2606-2610: 17.8161 %\n",
      "Accuracy of the network on test frames 2611-2615: 17.782 %\n",
      "Accuracy of the network on test frames 2616-2620: 17.7481 %\n",
      "Accuracy of the network on test frames 2621-2625: 17.7143 %\n",
      "Accuracy of the network on test frames 2626-2630: 17.6806 %\n",
      "Accuracy of the network on test frames 2631-2635: 17.723 %\n",
      "Accuracy of the network on test frames 2636-2640: 17.8788 %\n",
      "Accuracy of the network on test frames 2641-2645: 18.034 %\n",
      "Accuracy of the network on test frames 2646-2650: 18.1887 %\n",
      "Accuracy of the network on test frames 2651-2655: 18.3427 %\n",
      "Accuracy of the network on test frames 2656-2660: 18.4962 %\n",
      "Accuracy of the network on test frames 2661-2665: 18.6492 %\n",
      "Accuracy of the network on test frames 2666-2670: 18.764 %\n",
      "Accuracy of the network on test frames 2671-2675: 18.729 %\n",
      "Accuracy of the network on test frames 2676-2680: 18.694 %\n",
      "Accuracy of the network on test frames 2681-2685: 18.6592 %\n",
      "Accuracy of the network on test frames 2686-2690: 18.6245 %\n",
      "Accuracy of the network on test frames 2691-2695: 18.59 %\n",
      "Accuracy of the network on test frames 2696-2700: 18.5556 %\n",
      "Accuracy of the network on test frames 2701-2705: 18.5213 %\n",
      "Accuracy of the network on test frames 2706-2710: 18.4871 %\n",
      "Accuracy of the network on test frames 2711-2715: 18.453 %\n",
      "Accuracy of the network on test frames 2716-2720: 18.4191 %\n",
      "Accuracy of the network on test frames 2721-2725: 18.3853 %\n",
      "Accuracy of the network on test frames 2726-2730: 18.3516 %\n",
      "Accuracy of the network on test frames 2731-2735: 18.3181 %\n",
      "Accuracy of the network on test frames 2736-2740: 18.2847 %\n",
      "Accuracy of the network on test frames 2741-2745: 18.2514 %\n",
      "Accuracy of the network on test frames 2746-2750: 18.2182 %\n",
      "Accuracy of the network on test frames 2751-2755: 18.1851 %\n",
      "Accuracy of the network on test frames 2756-2760: 18.1522 %\n",
      "Accuracy of the network on test frames 2761-2765: 18.1193 %\n",
      "Accuracy of the network on test frames 2766-2770: 18.0866 %\n",
      "Accuracy of the network on test frames 2771-2775: 18.0541 %\n",
      "Accuracy of the network on test frames 2776-2780: 18.0216 %\n",
      "Accuracy of the network on test frames 2781-2785: 17.9892 %\n",
      "Accuracy of the network on test frames 2786-2790: 17.957 %\n",
      "Accuracy of the network on test frames 2791-2795: 17.9249 %\n",
      "Accuracy of the network on test frames 2796-2800: 17.8929 %\n",
      "Accuracy of the network on test frames 2801-2805: 17.861 %\n",
      "Accuracy of the network on test frames 2806-2810: 17.8292 %\n",
      "Accuracy of the network on test frames 2811-2815: 17.7975 %\n",
      "Accuracy of the network on test frames 2816-2820: 17.766 %\n",
      "Accuracy of the network on test frames 2821-2825: 17.8053 %\n",
      "Accuracy of the network on test frames 2826-2830: 17.9505 %\n",
      "Accuracy of the network on test frames 2831-2835: 18.0952 %\n",
      "Accuracy of the network on test frames 2836-2840: 18.2394 %\n",
      "Accuracy of the network on test frames 2841-2845: 18.3831 %\n",
      "Accuracy of the network on test frames 2846-2850: 18.5263 %\n",
      "Accuracy of the network on test frames 2851-2855: 18.669 %\n",
      "Accuracy of the network on test frames 2856-2860: 18.7762 %\n",
      "Accuracy of the network on test frames 2861-2865: 18.7435 %\n",
      "Accuracy of the network on test frames 2866-2870: 18.7108 %\n",
      "Accuracy of the network on test frames 2871-2875: 18.6783 %\n",
      "Accuracy of the network on test frames 2876-2880: 18.6458 %\n",
      "Accuracy of the network on test frames 2881-2885: 18.6135 %\n",
      "Accuracy of the network on test frames 2886-2890: 18.5813 %\n",
      "Accuracy of the network on test frames 2891-2895: 18.5492 %\n",
      "Accuracy of the network on test frames 2896-2900: 18.5172 %\n",
      "Accuracy of the network on test frames 2901-2905: 18.4854 %\n",
      "Accuracy of the network on test frames 2906-2910: 18.4536 %\n",
      "Accuracy of the network on test frames 2911-2915: 18.422 %\n",
      "Accuracy of the network on test frames 2916-2920: 18.3904 %\n",
      "Accuracy of the network on test frames 2921-2925: 18.359 %\n",
      "Accuracy of the network on test frames 2926-2930: 18.3276 %\n",
      "Accuracy of the network on test frames 2931-2935: 18.2964 %\n",
      "Accuracy of the network on test frames 2936-2940: 18.2653 %\n",
      "Accuracy of the network on test frames 2941-2945: 18.2343 %\n",
      "Accuracy of the network on test frames 2946-2950: 18.2219 %\n"
     ]
    }
   ],
   "source": [
    "# Test the saved model on the Test-Data\n",
    "\n",
    "# Only relevant for the plot\n",
    "# size_constraint = 100\n",
    "# figsize = (size_constraint//batch_size, size_constraint//batch_size)\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_data.shape[0], batch_size):\n",
    "                \n",
    "        inputs = torch.tensor(test_data.values[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        true_labels = torch.tensor(test_labels[i:i+batch_size]).to(device) #get_output_tensor(test_labels[i:i+batch_size]).to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += true_labels.size(0)\n",
    "        correct += (predicted == true_labels).sum().item()\n",
    "        \n",
    "        # Print the accuracy\n",
    "        print(f\"Accuracy of the network on test frames {i+1}-{i+batch_size}: {round(100 * correct / total, 4)} %\")\n",
    "        \n",
    "        # Plot the images\n",
    "        # f, axarr = plt.subplots(1, batch_size, figsize=figsize)\n",
    "        # for k in range(batch_size):   \n",
    "        #     axarr[k].imshow(test_data[i:i+batch_size][k], interpolation='nearest')\n",
    "        #     axarr[k].set_title(f\"Predicted: {labels[predicted[k]]},\\nActual: {labels[true_labels[k]]}\")\n",
    "        # plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
