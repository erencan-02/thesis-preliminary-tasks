{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 - Time Series\n",
    "Define, train, and test an ML model (preferably a neural network) to recognize the activity being performed in the following human activity recognition dataset: https://www.kaggle.com/datasets/uciml/human-activity-recognition-with-smartphones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "['STANDING', 'SITTING', 'LAYING', 'WALKING', 'WALKING_DOWNSTAIRS',\n",
    "       'WALKING_UPSTAIRS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path(task_number, *args):\n",
    "    notebook_path = os.path.abspath(f\"Task_{task_number}.ipynb\")\n",
    "    return os.path.join(os.path.dirname(notebook_path), *args)\n",
    "\n",
    "def preprocess_data(df, column=\"Activity\"):\n",
    "    le = LabelEncoder()\n",
    "    return  df.drop(column, axis=1), le.fit_transform(df[column])\n",
    "\n",
    "# Convert numpy array of output lables to one hot encoded tensor\n",
    "def get_output_tensor(array):\n",
    "    tensor = torch.zeros((len(array), 6), dtype=torch.float32)\n",
    "    for i, val in enumerate(array):\n",
    "        tensor[i][val] = 1\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Data Into Pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tBodyAcc-mean()-X</th>\n",
       "      <th>tBodyAcc-mean()-Y</th>\n",
       "      <th>tBodyAcc-mean()-Z</th>\n",
       "      <th>tBodyAcc-std()-X</th>\n",
       "      <th>tBodyAcc-std()-Y</th>\n",
       "      <th>tBodyAcc-std()-Z</th>\n",
       "      <th>tBodyAcc-mad()-X</th>\n",
       "      <th>tBodyAcc-mad()-Y</th>\n",
       "      <th>tBodyAcc-mad()-Z</th>\n",
       "      <th>tBodyAcc-max()-X</th>\n",
       "      <th>...</th>\n",
       "      <th>fBodyBodyGyroJerkMag-skewness()</th>\n",
       "      <th>fBodyBodyGyroJerkMag-kurtosis()</th>\n",
       "      <th>angle(tBodyAccMean,gravity)</th>\n",
       "      <th>angle(tBodyAccJerkMean),gravityMean)</th>\n",
       "      <th>angle(tBodyGyroMean,gravityMean)</th>\n",
       "      <th>angle(tBodyGyroJerkMean,gravityMean)</th>\n",
       "      <th>angle(X,gravityMean)</th>\n",
       "      <th>angle(Y,gravityMean)</th>\n",
       "      <th>angle(Z,gravityMean)</th>\n",
       "      <th>subject</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.288585</td>\n",
       "      <td>-0.020294</td>\n",
       "      <td>-0.132905</td>\n",
       "      <td>-0.995279</td>\n",
       "      <td>-0.983111</td>\n",
       "      <td>-0.913526</td>\n",
       "      <td>-0.995112</td>\n",
       "      <td>-0.983185</td>\n",
       "      <td>-0.923527</td>\n",
       "      <td>-0.934724</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.298676</td>\n",
       "      <td>-0.710304</td>\n",
       "      <td>-0.112754</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>-0.464761</td>\n",
       "      <td>-0.018446</td>\n",
       "      <td>-0.841247</td>\n",
       "      <td>0.179941</td>\n",
       "      <td>-0.058627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.278419</td>\n",
       "      <td>-0.016411</td>\n",
       "      <td>-0.123520</td>\n",
       "      <td>-0.998245</td>\n",
       "      <td>-0.975300</td>\n",
       "      <td>-0.960322</td>\n",
       "      <td>-0.998807</td>\n",
       "      <td>-0.974914</td>\n",
       "      <td>-0.957686</td>\n",
       "      <td>-0.943068</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.595051</td>\n",
       "      <td>-0.861499</td>\n",
       "      <td>0.053477</td>\n",
       "      <td>-0.007435</td>\n",
       "      <td>-0.732626</td>\n",
       "      <td>0.703511</td>\n",
       "      <td>-0.844788</td>\n",
       "      <td>0.180289</td>\n",
       "      <td>-0.054317</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.279653</td>\n",
       "      <td>-0.019467</td>\n",
       "      <td>-0.113462</td>\n",
       "      <td>-0.995380</td>\n",
       "      <td>-0.967187</td>\n",
       "      <td>-0.978944</td>\n",
       "      <td>-0.996520</td>\n",
       "      <td>-0.963668</td>\n",
       "      <td>-0.977469</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.390748</td>\n",
       "      <td>-0.760104</td>\n",
       "      <td>-0.118559</td>\n",
       "      <td>0.177899</td>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.808529</td>\n",
       "      <td>-0.848933</td>\n",
       "      <td>0.180637</td>\n",
       "      <td>-0.049118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279174</td>\n",
       "      <td>-0.026201</td>\n",
       "      <td>-0.123283</td>\n",
       "      <td>-0.996091</td>\n",
       "      <td>-0.983403</td>\n",
       "      <td>-0.990675</td>\n",
       "      <td>-0.997099</td>\n",
       "      <td>-0.982750</td>\n",
       "      <td>-0.989302</td>\n",
       "      <td>-0.938692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.117290</td>\n",
       "      <td>-0.482845</td>\n",
       "      <td>-0.036788</td>\n",
       "      <td>-0.012892</td>\n",
       "      <td>0.640011</td>\n",
       "      <td>-0.485366</td>\n",
       "      <td>-0.848649</td>\n",
       "      <td>0.181935</td>\n",
       "      <td>-0.047663</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.276629</td>\n",
       "      <td>-0.016570</td>\n",
       "      <td>-0.115362</td>\n",
       "      <td>-0.998139</td>\n",
       "      <td>-0.980817</td>\n",
       "      <td>-0.990482</td>\n",
       "      <td>-0.998321</td>\n",
       "      <td>-0.979672</td>\n",
       "      <td>-0.990441</td>\n",
       "      <td>-0.942469</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351471</td>\n",
       "      <td>-0.699205</td>\n",
       "      <td>0.123320</td>\n",
       "      <td>0.122542</td>\n",
       "      <td>0.693578</td>\n",
       "      <td>-0.615971</td>\n",
       "      <td>-0.847865</td>\n",
       "      <td>0.185151</td>\n",
       "      <td>-0.043892</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tBodyAcc-mean()-X  tBodyAcc-mean()-Y  tBodyAcc-mean()-Z  tBodyAcc-std()-X  \\\n",
       "0           0.288585          -0.020294          -0.132905         -0.995279   \n",
       "1           0.278419          -0.016411          -0.123520         -0.998245   \n",
       "2           0.279653          -0.019467          -0.113462         -0.995380   \n",
       "3           0.279174          -0.026201          -0.123283         -0.996091   \n",
       "4           0.276629          -0.016570          -0.115362         -0.998139   \n",
       "\n",
       "   tBodyAcc-std()-Y  tBodyAcc-std()-Z  tBodyAcc-mad()-X  tBodyAcc-mad()-Y  \\\n",
       "0         -0.983111         -0.913526         -0.995112         -0.983185   \n",
       "1         -0.975300         -0.960322         -0.998807         -0.974914   \n",
       "2         -0.967187         -0.978944         -0.996520         -0.963668   \n",
       "3         -0.983403         -0.990675         -0.997099         -0.982750   \n",
       "4         -0.980817         -0.990482         -0.998321         -0.979672   \n",
       "\n",
       "   tBodyAcc-mad()-Z  tBodyAcc-max()-X  ...  fBodyBodyGyroJerkMag-skewness()  \\\n",
       "0         -0.923527         -0.934724  ...                        -0.298676   \n",
       "1         -0.957686         -0.943068  ...                        -0.595051   \n",
       "2         -0.977469         -0.938692  ...                        -0.390748   \n",
       "3         -0.989302         -0.938692  ...                        -0.117290   \n",
       "4         -0.990441         -0.942469  ...                        -0.351471   \n",
       "\n",
       "   fBodyBodyGyroJerkMag-kurtosis()  angle(tBodyAccMean,gravity)  \\\n",
       "0                        -0.710304                    -0.112754   \n",
       "1                        -0.861499                     0.053477   \n",
       "2                        -0.760104                    -0.118559   \n",
       "3                        -0.482845                    -0.036788   \n",
       "4                        -0.699205                     0.123320   \n",
       "\n",
       "   angle(tBodyAccJerkMean),gravityMean)  angle(tBodyGyroMean,gravityMean)  \\\n",
       "0                              0.030400                         -0.464761   \n",
       "1                             -0.007435                         -0.732626   \n",
       "2                              0.177899                          0.100699   \n",
       "3                             -0.012892                          0.640011   \n",
       "4                              0.122542                          0.693578   \n",
       "\n",
       "   angle(tBodyGyroJerkMean,gravityMean)  angle(X,gravityMean)  \\\n",
       "0                             -0.018446             -0.841247   \n",
       "1                              0.703511             -0.844788   \n",
       "2                              0.808529             -0.848933   \n",
       "3                             -0.485366             -0.848649   \n",
       "4                             -0.615971             -0.847865   \n",
       "\n",
       "   angle(Y,gravityMean)  angle(Z,gravityMean)  subject  \n",
       "0              0.179941             -0.058627        1  \n",
       "1              0.180289             -0.054317        1  \n",
       "2              0.180637             -0.049118        1  \n",
       "3              0.181935             -0.047663        1  \n",
       "4              0.185151             -0.043892        1  \n",
       "\n",
       "[5 rows x 562 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_PATH = get_path(2, \"model\", \"activity_loc_rnn.pt\")\n",
    "\n",
    "train_data = pd.read_csv(get_path(2, \"data\", \"train.csv\"))\n",
    "test_data = pd.read_csv(get_path(2, \"data\", \"test.csv\"))\n",
    "\n",
    "# Split into label and features\n",
    "train_data, train_labels = preprocess_data(train_data)\n",
    "test_data, test_labels = preprocess_data(test_data)\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return np.array(self.X.values[idx], dtype=np.float32), np.array(self.Y[idx], dtype=np.float32)\n",
    "\n",
    "train_dataset = TimeSeriesDataset(train_data, train_labels)\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Neural Network\n",
    "In this case we want an MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Initialize hidden and cell states \n",
    "        h0 = torch.zeros(self.num_layers, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, self.hidden_size).to(x.device)\n",
    "\n",
    "        # Forward propagate LSTM\n",
    "        out, _ = self.lstm(x, (h0, c0))  \n",
    "        \n",
    "        out = self.fc(out)\n",
    "\n",
    "        # Decode the hidden state of the last time step\n",
    "        #out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Network Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 562\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 6\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [1/114], Loss: 1.1203\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [2/114], Loss: 1.0185\n",
      "Epoch [1/50], Step [3/114], Loss: 1.1029\n",
      "Epoch [1/50], Step [4/114], Loss: 1.0604\n",
      "Epoch [1/50], Step [5/114], Loss: 1.0102\n",
      "Epoch [1/50], Step [6/114], Loss: 1.1228\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [7/114], Loss: 1.0435\n",
      "Epoch [1/50], Step [8/114], Loss: 1.0655\n",
      "Epoch [1/50], Step [9/114], Loss: 1.1438\n",
      "Epoch [1/50], Step [10/114], Loss: 1.0011\n",
      "Epoch [1/50], Step [11/114], Loss: 1.1627\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [12/114], Loss: 1.0987\n",
      "Epoch [1/50], Step [13/114], Loss: 0.9999\n",
      "Epoch [1/50], Step [14/114], Loss: 1.1469\n",
      "Epoch [1/50], Step [15/114], Loss: 1.0042\n",
      "Epoch [1/50], Step [16/114], Loss: 1.1412\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [17/114], Loss: 1.0694\n",
      "Epoch [1/50], Step [18/114], Loss: 1.0316\n",
      "Epoch [1/50], Step [19/114], Loss: 1.1635\n",
      "Epoch [1/50], Step [20/114], Loss: 0.9725\n",
      "Epoch [1/50], Step [21/114], Loss: 1.1232\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [22/114], Loss: 1.0819\n",
      "Epoch [1/50], Step [23/114], Loss: 1.0741\n",
      "Epoch [1/50], Step [24/114], Loss: 1.1291\n",
      "Epoch [1/50], Step [25/114], Loss: 1.0344\n",
      "Epoch [1/50], Step [26/114], Loss: 1.1353\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [27/114], Loss: 1.0136\n",
      "Epoch [1/50], Step [28/114], Loss: 1.1318\n",
      "Epoch [1/50], Step [29/114], Loss: 1.0812\n",
      "Epoch [1/50], Step [30/114], Loss: 1.0591\n",
      "Epoch [1/50], Step [31/114], Loss: 1.0920\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [32/114], Loss: 1.0167\n",
      "Epoch [1/50], Step [33/114], Loss: 1.1528\n",
      "Epoch [1/50], Step [34/114], Loss: 1.0028\n",
      "Epoch [1/50], Step [35/114], Loss: 1.1065\n",
      "Epoch [1/50], Step [36/114], Loss: 1.1055\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [37/114], Loss: 1.0047\n",
      "Epoch [1/50], Step [38/114], Loss: 1.1591\n",
      "Epoch [1/50], Step [39/114], Loss: 1.0887\n",
      "Epoch [1/50], Step [40/114], Loss: 1.0693\n",
      "Epoch [1/50], Step [41/114], Loss: 1.1140\n",
      "Model saved at c:\\Users\\Admin\\Desktop\\Uni\\Thesis\\Preliminary Tasks\\Task 2\\model\\activity_loc_rnn.pt\n",
      "Epoch [1/50], Step [42/114], Loss: 1.0009\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[184], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Backward pass and optimization\u001b[39;00m\n\u001b[0;32m     25\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 26\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# print loss\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\cv1\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Admin\\miniconda3\\envs\\cv1\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 1e-4\n",
    "num_epochs = 50\n",
    "batch_size = 64\n",
    "save_steps = 5\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD (model.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "dataset = TimeSeriesDataset(train_data, train_labels)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Iterate through number of epochs and determine next step\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(dataloader):\n",
    "        \n",
    "        # Get input and labels\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs.float())\n",
    "        loss = criterion(outputs, labels.long())\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # print loss\n",
    "        print (f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{train_data.shape[0]//batch_size}], Loss: {loss:.4f}\")\n",
    "        \n",
    "      \n",
    "        # Save the model here, in case of interruption or if I'm bored cause my cpu too slow  \n",
    "        # Save every [save_steps] steps\n",
    "        if i % save_steps == 0:\n",
    "            torch.save(model.state_dict(), MODEL_PATH)\n",
    "            print(\"Model saved at\", MODEL_PATH)\n",
    "\n",
    "\n",
    "print(\"Training finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), MODEL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(562, 256, num_layers=2, batch_first=True)\n",
       "  (fc): Linear(in_features=256, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(input_size, hidden_size, num_layers, num_classes)\n",
    "model.load_state_dict(torch.load(MODEL_PATH))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on test frames 1-64: 15.625 %\n",
      "Accuracy of the network on test frames 65-128: 48.4375 %\n",
      "Accuracy of the network on test frames 129-192: 33.8542 %\n",
      "Accuracy of the network on test frames 193-256: 46.0938 %\n",
      "Accuracy of the network on test frames 257-320: 43.4375 %\n",
      "Accuracy of the network on test frames 321-384: 44.2708 %\n",
      "Accuracy of the network on test frames 385-448: 44.6429 %\n",
      "Accuracy of the network on test frames 449-512: 39.4531 %\n",
      "Accuracy of the network on test frames 513-576: 44.2708 %\n",
      "Accuracy of the network on test frames 577-640: 40.1562 %\n",
      "Accuracy of the network on test frames 641-704: 42.0455 %\n",
      "Accuracy of the network on test frames 705-768: 40.7552 %\n",
      "Accuracy of the network on test frames 769-832: 40.2644 %\n",
      "Accuracy of the network on test frames 833-896: 41.8527 %\n",
      "Accuracy of the network on test frames 897-960: 40.2083 %\n",
      "Accuracy of the network on test frames 961-1024: 43.8477 %\n",
      "Accuracy of the network on test frames 1025-1088: 41.8199 %\n",
      "Accuracy of the network on test frames 1089-1152: 43.5764 %\n",
      "Accuracy of the network on test frames 1153-1216: 43.2566 %\n",
      "Accuracy of the network on test frames 1217-1280: 43.0469 %\n",
      "Accuracy of the network on test frames 1281-1344: 43.2292 %\n",
      "Accuracy of the network on test frames 1345-1408: 41.3352 %\n",
      "Accuracy of the network on test frames 1409-1472: 43.1386 %\n",
      "Accuracy of the network on test frames 1473-1536: 42.8385 %\n",
      "Accuracy of the network on test frames 1537-1600: 42.9375 %\n",
      "Accuracy of the network on test frames 1601-1664: 43.9303 %\n",
      "Accuracy of the network on test frames 1665-1728: 42.3611 %\n",
      "Accuracy of the network on test frames 1729-1792: 43.3036 %\n",
      "Accuracy of the network on test frames 1793-1856: 43.319 %\n",
      "Accuracy of the network on test frames 1857-1920: 42.0312 %\n",
      "Accuracy of the network on test frames 1921-1984: 43.5988 %\n",
      "Accuracy of the network on test frames 1985-2048: 42.2363 %\n",
      "Accuracy of the network on test frames 2049-2112: 41.7614 %\n",
      "Accuracy of the network on test frames 2113-2176: 42.5092 %\n",
      "Accuracy of the network on test frames 2177-2240: 41.3393 %\n",
      "Accuracy of the network on test frames 2241-2304: 41.0156 %\n",
      "Accuracy of the network on test frames 2305-2368: 41.4274 %\n",
      "Accuracy of the network on test frames 2369-2432: 40.4194 %\n",
      "Accuracy of the network on test frames 2433-2496: 40.8654 %\n",
      "Accuracy of the network on test frames 2497-2560: 40.7422 %\n",
      "Accuracy of the network on test frames 2561-2624: 39.8247 %\n",
      "Accuracy of the network on test frames 2625-2688: 40.9226 %\n",
      "Accuracy of the network on test frames 2689-2752: 41.1701 %\n",
      "Accuracy of the network on test frames 2753-2816: 40.3054 %\n",
      "Accuracy of the network on test frames 2817-2880: 41.3889 %\n",
      "Accuracy of the network on test frames 2881-2944: 41.644 %\n",
      "Accuracy of the network on test frames 2945-3008: 41.6356 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i in range(0, test_data.shape[0], batch_size):\n",
    "                \n",
    "        inputs = torch.tensor(test_data.values[i:i+batch_size], dtype=torch.float32).to(device)\n",
    "        true_labels = torch.tensor(test_labels[i:i+batch_size]).to(device) #get_output_tensor(test_labels[i:i+batch_size]).to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += true_labels.size(0)\n",
    "        correct += (predicted == true_labels).sum().item()\n",
    "        \n",
    "        print(f\"Accuracy of the network on test frames {i+1}-{i+batch_size}: {round(100 * correct / total, 4)} %\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
